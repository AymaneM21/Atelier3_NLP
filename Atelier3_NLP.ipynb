{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00dd9165-715a-4263-af25-9608edcdabc8",
   "metadata": {},
   "source": [
    "## 0- Importing the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "588be92e-6e29-43f4-be9e-1e9a0062c17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, log_loss\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca83a33a-787b-4f08-b9f7-45d3aec0ef19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download necessary NLTK data files\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ba7514-41b7-47cf-a97f-e0ba56178271",
   "metadata": {},
   "source": [
    "## Part 1: Language Modeling / Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b616282a-9909-48b5-9933-b828bc39dbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"answers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2a17fd2-0cfe-4c0b-bb92-170860289e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>answer</th>\n",
       "      <th>score</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>High risk problems are address in the prototyp...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.1</td>\n",
       "      <td>To simulate portions of the desired final prod...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.1</td>\n",
       "      <td>A prototype program simulates the behaviors of...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.1</td>\n",
       "      <td>Defined in the Specification phase a prototype...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.1</td>\n",
       "      <td>It is used to let the users have a first idea ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2437</th>\n",
       "      <td>12.1</td>\n",
       "      <td>log n</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>12.1</td>\n",
       "      <td>minus 1 divided by 2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>12.1</td>\n",
       "      <td>2n-1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>12.1</td>\n",
       "      <td>it takes at most h steps, where h is the heigh...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>12.1</td>\n",
       "      <td>it depends on the install search tree then fro...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2442 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                             answer  score  correct\n",
       "0      1.1  High risk problems are address in the prototyp...    3.5      0.0\n",
       "1      1.1  To simulate portions of the desired final prod...    5.0      1.0\n",
       "2      1.1  A prototype program simulates the behaviors of...    4.0      1.0\n",
       "3      1.1  Defined in the Specification phase a prototype...    5.0      1.0\n",
       "4      1.1  It is used to let the users have a first idea ...    3.0      0.0\n",
       "...    ...                                                ...    ...      ...\n",
       "2437  12.1                                              log n    5.0      1.0\n",
       "2438  12.1                               minus 1 divided by 2    1.5      0.0\n",
       "2439  12.1                                               2n-1    2.5      0.0\n",
       "2440  12.1  it takes at most h steps, where h is the heigh...    5.0      1.0\n",
       "2441  12.1  it depends on the install search tree then fro...    1.5      0.0\n",
       "\n",
       "[2442 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e03657-dc8d-458b-8dcf-f87122f0ab60",
   "metadata": {},
   "source": [
    "### 1. Establish a preprocessing NLP pipeline (Tokenization stemming lemmatization, Stop words,Discretization, etc) off the collected Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e675fea-f847-4bd8-a7d5-a799414d0f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing functions\n",
    "def preprocess(text):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    # Stop words removal\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    # Stemming and Lemmatization\n",
    "    stemmer = PorterStemmer()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(stemmer.stem(word)) for word in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing to the dataset\n",
    "data['processed_answer'] = data['answer'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "718d882b-bcb1-4f84-8b44-6e1b2c759628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>answer</th>\n",
       "      <th>score</th>\n",
       "      <th>correct</th>\n",
       "      <th>processed_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>High risk problems are address in the prototyp...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>high risk problem address prototyp program mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.1</td>\n",
       "      <td>To simulate portions of the desired final prod...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>simul portion desir final product quick easi p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.1</td>\n",
       "      <td>A prototype program simulates the behaviors of...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>prototyp program simul behavior portion desir ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.1</td>\n",
       "      <td>Defined in the Specification phase a prototype...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>defin specif phase prototyp stimul behavior po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.1</td>\n",
       "      <td>It is used to let the users have a first idea ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>use let user first idea complet program allow ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2437</th>\n",
       "      <td>12.1</td>\n",
       "      <td>log n</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>log n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>12.1</td>\n",
       "      <td>minus 1 divided by 2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>minu 1 divid 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>12.1</td>\n",
       "      <td>2n-1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2n-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>12.1</td>\n",
       "      <td>it takes at most h steps, where h is the heigh...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>take h step , h height tree .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>12.1</td>\n",
       "      <td>it depends on the install search tree then fro...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>depend instal search tree whatev case repeat b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2442 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                             answer  score  correct  \\\n",
       "0      1.1  High risk problems are address in the prototyp...    3.5      0.0   \n",
       "1      1.1  To simulate portions of the desired final prod...    5.0      1.0   \n",
       "2      1.1  A prototype program simulates the behaviors of...    4.0      1.0   \n",
       "3      1.1  Defined in the Specification phase a prototype...    5.0      1.0   \n",
       "4      1.1  It is used to let the users have a first idea ...    3.0      0.0   \n",
       "...    ...                                                ...    ...      ...   \n",
       "2437  12.1                                              log n    5.0      1.0   \n",
       "2438  12.1                               minus 1 divided by 2    1.5      0.0   \n",
       "2439  12.1                                               2n-1    2.5      0.0   \n",
       "2440  12.1  it takes at most h steps, where h is the heigh...    5.0      1.0   \n",
       "2441  12.1  it depends on the install search tree then fro...    1.5      0.0   \n",
       "\n",
       "                                       processed_answer  \n",
       "0     high risk problem address prototyp program mak...  \n",
       "1     simul portion desir final product quick easi p...  \n",
       "2     prototyp program simul behavior portion desir ...  \n",
       "3     defin specif phase prototyp stimul behavior po...  \n",
       "4     use let user first idea complet program allow ...  \n",
       "...                                                 ...  \n",
       "2437                                              log n  \n",
       "2438                                     minu 1 divid 2  \n",
       "2439                                               2n-1  \n",
       "2440                      take h step , h height tree .  \n",
       "2441  depend instal search tree whatev case repeat b...  \n",
       "\n",
       "[2442 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fed273-7673-42e5-b1a7-f0883d7b6db2",
   "metadata": {},
   "source": [
    "### 2. Encode your Data vectors By using Word2vec (CBOW, Skip Gram), Bag Of words, TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86f938f7-3324-4fc9-badf-80004a048db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of Words\n",
    "vectorizer = CountVectorizer()\n",
    "X_bow = vectorizer.fit_transform(data['processed_answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d86ba3d-1510-4bcf-821b-030b5d94728b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(data['processed_answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a89892a-fd1f-469e-adb9-46adddd9762a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec\n",
    "tokenized_sentences = [sentence.split() for sentence in data['processed_answer']]\n",
    "w2v_model_cbow = Word2Vec(sentences=tokenized_sentences, vector_size=100, window=5, min_count=1, sg=0)\n",
    "w2v_model_sg = Word2Vec(sentences=tokenized_sentences, vector_size=100, window=5, min_count=1, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3cc61268-0f41-4960-ad04-04f9b51f0c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_w2v_embeddings(model, sentences):\n",
    "    return np.array([np.mean([model.wv[word] for word in sentence if word in model.wv] or [np.zeros(model.vector_size)], axis=0) for sentence in sentences])\n",
    "\n",
    "X_w2v_cbow = get_w2v_embeddings(w2v_model_cbow, tokenized_sentences)\n",
    "X_w2v_sg = get_w2v_embeddings(w2v_model_sg, tokenized_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d73bc56b-a15d-4a99-a200-a39df907dcf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.19785336e-03,  2.73047864e-01, -2.39131935e-02, ...,\n",
       "        -4.36109185e-01,  3.35062854e-02,  2.16538310e-02],\n",
       "       [-9.06412824e-05,  2.26658508e-01, -1.75846610e-02, ...,\n",
       "        -3.64665151e-01,  2.92883366e-02,  1.58888213e-02],\n",
       "       [ 1.65670167e-03,  2.58940816e-01, -1.89552307e-02, ...,\n",
       "        -4.11310345e-01,  3.01752444e-02,  2.26086620e-02],\n",
       "       ...,\n",
       "       [ 9.49640945e-03, -4.15351847e-03,  9.47525259e-03, ...,\n",
       "        -3.25483805e-03, -4.43130499e-03, -9.75177530e-03],\n",
       "       [ 2.63799424e-03,  3.05080116e-01, -2.35623121e-02, ...,\n",
       "        -4.87523764e-01,  3.33693251e-02,  2.36712657e-02],\n",
       "       [ 4.71543474e-03,  2.43698835e-01, -2.06081383e-02, ...,\n",
       "        -3.92173409e-01,  2.60883942e-02,  1.86806507e-02]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_w2v_cbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "060f2d44-f59c-4962-a5b7-00a2df7b4e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0663745 ,  0.07068023,  0.0333822 , ..., -0.26407805,\n",
       "         0.03448671,  0.06719125],\n",
       "       [ 0.08701642,  0.05700462,  0.04260639, ..., -0.3011708 ,\n",
       "         0.04454111,  0.0663107 ],\n",
       "       [ 0.08238015,  0.07518212,  0.04479032, ..., -0.29147175,\n",
       "         0.02598211,  0.08104239],\n",
       "       ...,\n",
       "       [ 0.00949641, -0.00415352,  0.00947525, ..., -0.00325484,\n",
       "        -0.0044313 , -0.00975178],\n",
       "       [ 0.14804503,  0.00846315,  0.0711785 , ..., -0.28758466,\n",
       "         0.01871211,  0.10465664],\n",
       "       [ 0.14307608,  0.00509189,  0.06607483, ..., -0.29411992,\n",
       "         0.01885466,  0.08715545]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_w2v_sg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bd2054-1c37-4fc6-b3bf-9dd791abcc89",
   "metadata": {},
   "source": [
    "### 3. Train your models by using SVR, Naive Bayes, Linear Regression , Decision Tree Algorithms (The embedding will be done by Word2Vec)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0bdc3de1-1e0d-401c-9c8d-61251e6a2fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target variable\n",
    "y = data['score']\n",
    "\n",
    "# Split the data\n",
    "X_train_w2v_cbow, X_test_w2v_cbow, y_train, y_test = train_test_split(X_w2v_cbow, y, test_size=0.2, random_state=42)\n",
    "X_train_w2v_sg, X_test_w2v_sg, y_train, y_test = train_test_split(X_w2v_sg, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "148f6e75-d9c9-41d8-b06c-afdd8d88f6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    'SVR': SVR(),\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Decision Tree': DecisionTreeRegressor()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "09146370-918a-47f4-8f64-1d38bea0b90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and evaluate models\n",
    "def train_evaluate(models, X_train, X_test, y_train, y_test):\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, predictions)\n",
    "        results[name] = mse\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "24430f80-f07b-4770-b203-04fbda39f6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models\n",
    "results_cbow = train_evaluate(models, X_train_w2v_cbow, X_test_w2v_cbow, y_train, y_test)\n",
    "results_sg = train_evaluate(models, X_train_w2v_sg, X_test_w2v_sg, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "06316102-c7db-4a3a-989d-1a3c890dd085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results using CBOW Word2Vec:\n",
      "{'SVR': 1.700611231571335, 'Linear Regression': 1.1131646775439066, 'Decision Tree': 2.0311618098159507}\n",
      "\n",
      "Results using Skip Gram Word2Vec:\n",
      "{'SVR': 1.4915537351871, 'Linear Regression': 1.0848127191439936, 'Decision Tree': 1.656768916155419}\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "print(\"Results using CBOW Word2Vec:\")\n",
    "print(results_cbow)\n",
    "print(\"\\nResults using Skip Gram Word2Vec:\")\n",
    "print(results_sg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fdf5e3-d600-4844-b67c-7871989de090",
   "metadata": {},
   "source": [
    "### 4. Evaluate the four languages models by using standards metrics (MSE , RMSE, etc), choose the best model then argument your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6c52c07e-d77a-4599-b257-9c1d89a7c1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate the best model\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    predictions = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return mse, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2e93bd23-2093-4c5f-989a-d8e4b8680af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model using CBOW: Linear Regression\n",
      "MSE: 222.27310097328848, RMSE: 14.90882627752059\n"
     ]
    }
   ],
   "source": [
    "# best model using CBOW\n",
    "best_model_name_cbow = min(results_cbow, key=results_cbow.get)\n",
    "best_model_cbow = models[best_model_name_cbow]\n",
    "mse_cbow, rmse_cbow = evaluate_model(best_model_cbow, X_test_w2v_cbow, y_test)\n",
    "print(f\"Best Model using CBOW: {best_model_name_cbow}\")\n",
    "print(f\"MSE: {mse_cbow}, RMSE: {rmse_cbow}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3438c80d-ce3b-4285-af5c-992c17150e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model using Skip Gram: Linear Regression\n",
      "MSE: 1.0848127191439936, RMSE: 1.0415434312327037\n"
     ]
    }
   ],
   "source": [
    "#  best model using Skip Gram\n",
    "best_model_name_sg = min(results_sg, key=results_sg.get)\n",
    "best_model_sg = models[best_model_name_sg]\n",
    "mse_sg, rmse_sg = evaluate_model(best_model_sg, X_test_w2v_sg, y_test)\n",
    "print(f\"Best Model using Skip Gram: {best_model_name_sg}\")\n",
    "print(f\"MSE: {mse_sg}, RMSE: {rmse_sg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5373340b-6b48-4a9b-883c-f5ec48fbea01",
   "metadata": {},
   "source": [
    "Linear Regression demonstrated the lowest MSE and RMSE values across both CBOW and Skip Gram embeddings. Lower MSE and RMSE values indicate that the predictions made by Linear Regression are closer to the actual scores, signifying higher accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70b4d82-a400-479d-9ef0-2990da79bb3f",
   "metadata": {},
   "source": [
    "### 5. Interpret the Obtained Results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936e5cdd-feb0-405d-ba25-56262438358e",
   "metadata": {},
   "source": [
    "Linear Regression stands out as the best model for this task due to its superior performance metrics, simplicity, and interpretability. The low MSE and RMSE values indicate accurate and reliable predictions, making it an excellent choice for automating the scoring of short answer questions. The insights gained from the model can also aid in enhancing the educational feedback process, providing valuable information for both educators and students."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697a6147-342d-470e-acbb-3c83c75abe30",
   "metadata": {},
   "source": [
    "## Part 2: Language Modeling / Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f0ec0944-e3d7-417b-bc63-072fb367bf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data2 = pd.read_csv(\"twitter_training.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f07fccda-5383-4975-bcfe-c2c5c1461016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2401</th>\n",
       "      <th>Borderlands</th>\n",
       "      <th>Positive</th>\n",
       "      <th>im getting on borderlands and i will murder you all ,</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting into borderlands and i can murder y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74676</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that the Windows partition of my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74677</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that my Mac window partition is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74678</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized the windows partition of my Mac ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74679</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized between the windows partition of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74680</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just like the windows partition of my Mac is l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74681 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       2401  Borderlands  Positive  \\\n",
       "0      2401  Borderlands  Positive   \n",
       "1      2401  Borderlands  Positive   \n",
       "2      2401  Borderlands  Positive   \n",
       "3      2401  Borderlands  Positive   \n",
       "4      2401  Borderlands  Positive   \n",
       "...     ...          ...       ...   \n",
       "74676  9200       Nvidia  Positive   \n",
       "74677  9200       Nvidia  Positive   \n",
       "74678  9200       Nvidia  Positive   \n",
       "74679  9200       Nvidia  Positive   \n",
       "74680  9200       Nvidia  Positive   \n",
       "\n",
       "      im getting on borderlands and i will murder you all ,  \n",
       "0      I am coming to the borders and I will kill you...     \n",
       "1      im getting on borderlands and i will kill you ...     \n",
       "2      im coming on borderlands and i will murder you...     \n",
       "3      im getting on borderlands 2 and i will murder ...     \n",
       "4      im getting into borderlands and i can murder y...     \n",
       "...                                                  ...     \n",
       "74676  Just realized that the Windows partition of my...     \n",
       "74677  Just realized that my Mac window partition is ...     \n",
       "74678  Just realized the windows partition of my Mac ...     \n",
       "74679  Just realized between the windows partition of...     \n",
       "74680  Just like the windows partition of my Mac is l...     \n",
       "\n",
       "[74681 rows x 4 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b5913690-8f10-482a-8fd3-fad9494c77dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide column names manually (replace with actual column names)\n",
    "columns = [\"Tweet ID\", \"Entity\", \"Sentiment\", \"Tweet_content\"]\n",
    "data2.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "07a8e274-ce30-403b-b321-877da6323f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>Entity</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tweet_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting into borderlands and i can murder y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74676</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that the Windows partition of my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74677</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that my Mac window partition is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74678</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized the windows partition of my Mac ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74679</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized between the windows partition of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74680</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just like the windows partition of my Mac is l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74681 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Tweet ID       Entity Sentiment  \\\n",
       "0          2401  Borderlands  Positive   \n",
       "1          2401  Borderlands  Positive   \n",
       "2          2401  Borderlands  Positive   \n",
       "3          2401  Borderlands  Positive   \n",
       "4          2401  Borderlands  Positive   \n",
       "...         ...          ...       ...   \n",
       "74676      9200       Nvidia  Positive   \n",
       "74677      9200       Nvidia  Positive   \n",
       "74678      9200       Nvidia  Positive   \n",
       "74679      9200       Nvidia  Positive   \n",
       "74680      9200       Nvidia  Positive   \n",
       "\n",
       "                                           Tweet_content  \n",
       "0      I am coming to the borders and I will kill you...  \n",
       "1      im getting on borderlands and i will kill you ...  \n",
       "2      im coming on borderlands and i will murder you...  \n",
       "3      im getting on borderlands 2 and i will murder ...  \n",
       "4      im getting into borderlands and i can murder y...  \n",
       "...                                                  ...  \n",
       "74676  Just realized that the Windows partition of my...  \n",
       "74677  Just realized that my Mac window partition is ...  \n",
       "74678  Just realized the windows partition of my Mac ...  \n",
       "74679  Just realized between the windows partition of...  \n",
       "74680  Just like the windows partition of my Mac is l...  \n",
       "\n",
       "[74681 rows x 4 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484face4-8e97-463b-96fd-63a59b75660b",
   "metadata": {},
   "source": [
    "### 1. Establish a preprocessing NLP pipeline (Tokenization stemming lemmatization, Stop words,Discretization, etc) off the collected Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "82afb726-9cdd-4bdc-9118-4826e1d48f2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    if isinstance(text, str):\n",
    "        # Tokenization\n",
    "        tokens = word_tokenize(text.lower())\n",
    "        \n",
    "        # Stop words removal\n",
    "        tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "        \n",
    "        # Stemming and Lemmatization\n",
    "        stemmer = PorterStemmer()\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        tokens = [lemmatizer.lemmatize(stemmer.stem(word)) for word in tokens]\n",
    "        \n",
    "        return ' '.join(tokens)\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "# Apply preprocessing\n",
    "data2['processed_content'] = data2['Tweet_content'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c979dd23-931f-4cf7-bfd9-991001712af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>Entity</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tweet_content</th>\n",
       "      <th>processed_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "      <td>come border kill ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "      <td>im get borderland kill ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "      <td>im come borderland murder ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "      <td>im get borderland 2 murder ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting into borderlands and i can murder y...</td>\n",
       "      <td>im get borderland murder ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74676</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that the Windows partition of my...</td>\n",
       "      <td>realiz window partit mac like 6 year behind nv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74677</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that my Mac window partition is ...</td>\n",
       "      <td>realiz mac window partit 6 year behind nvidia ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74678</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized the windows partition of my Mac ...</td>\n",
       "      <td>realiz window partit mac 6 year behind nvidia ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74679</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized between the windows partition of...</td>\n",
       "      <td>realiz window partit mac like 6 year behind nv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74680</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just like the windows partition of my Mac is l...</td>\n",
       "      <td>like window partit mac like 6 year behind driv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74681 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Tweet ID       Entity Sentiment  \\\n",
       "0          2401  Borderlands  Positive   \n",
       "1          2401  Borderlands  Positive   \n",
       "2          2401  Borderlands  Positive   \n",
       "3          2401  Borderlands  Positive   \n",
       "4          2401  Borderlands  Positive   \n",
       "...         ...          ...       ...   \n",
       "74676      9200       Nvidia  Positive   \n",
       "74677      9200       Nvidia  Positive   \n",
       "74678      9200       Nvidia  Positive   \n",
       "74679      9200       Nvidia  Positive   \n",
       "74680      9200       Nvidia  Positive   \n",
       "\n",
       "                                           Tweet_content  \\\n",
       "0      I am coming to the borders and I will kill you...   \n",
       "1      im getting on borderlands and i will kill you ...   \n",
       "2      im coming on borderlands and i will murder you...   \n",
       "3      im getting on borderlands 2 and i will murder ...   \n",
       "4      im getting into borderlands and i can murder y...   \n",
       "...                                                  ...   \n",
       "74676  Just realized that the Windows partition of my...   \n",
       "74677  Just realized that my Mac window partition is ...   \n",
       "74678  Just realized the windows partition of my Mac ...   \n",
       "74679  Just realized between the windows partition of...   \n",
       "74680  Just like the windows partition of my Mac is l...   \n",
       "\n",
       "                                       processed_content  \n",
       "0                                     come border kill ,  \n",
       "1                               im get borderland kill ,  \n",
       "2                            im come borderland murder ,  \n",
       "3                           im get borderland 2 murder ,  \n",
       "4                             im get borderland murder ,  \n",
       "...                                                  ...  \n",
       "74676  realiz window partit mac like 6 year behind nv...  \n",
       "74677  realiz mac window partit 6 year behind nvidia ...  \n",
       "74678  realiz window partit mac 6 year behind nvidia ...  \n",
       "74679  realiz window partit mac like 6 year behind nv...  \n",
       "74680  like window partit mac like 6 year behind driv...  \n",
       "\n",
       "[74681 rows x 5 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8cd8d7f1-96e3-43b9-9223-c123f4670361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the clean_and_lowercase function\n",
    "def clean(text):\n",
    "    # Remove special characters, punctuation, and unnecessary symbols\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Return the cleaned text\n",
    "    return cleaned_text\n",
    "\n",
    "# Apply cleaning\n",
    "data2['processed_content'] = data2['processed_content'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "88cd2896-3e09-49d0-8d59-059b037e49ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>Entity</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tweet_content</th>\n",
       "      <th>processed_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "      <td>come border kill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "      <td>im get borderland kill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "      <td>im come borderland murder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "      <td>im get borderland  murder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting into borderlands and i can murder y...</td>\n",
       "      <td>im get borderland murder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74676</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that the Windows partition of my...</td>\n",
       "      <td>realiz window partit mac like  year behind nvi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74677</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that my Mac window partition is ...</td>\n",
       "      <td>realiz mac window partit  year behind nvidia d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74678</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized the windows partition of my Mac ...</td>\n",
       "      <td>realiz window partit mac  year behind nvidia d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74679</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized between the windows partition of...</td>\n",
       "      <td>realiz window partit mac like  year behind nvi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74680</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just like the windows partition of my Mac is l...</td>\n",
       "      <td>like window partit mac like  year behind drive...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74681 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Tweet ID       Entity Sentiment  \\\n",
       "0          2401  Borderlands  Positive   \n",
       "1          2401  Borderlands  Positive   \n",
       "2          2401  Borderlands  Positive   \n",
       "3          2401  Borderlands  Positive   \n",
       "4          2401  Borderlands  Positive   \n",
       "...         ...          ...       ...   \n",
       "74676      9200       Nvidia  Positive   \n",
       "74677      9200       Nvidia  Positive   \n",
       "74678      9200       Nvidia  Positive   \n",
       "74679      9200       Nvidia  Positive   \n",
       "74680      9200       Nvidia  Positive   \n",
       "\n",
       "                                           Tweet_content  \\\n",
       "0      I am coming to the borders and I will kill you...   \n",
       "1      im getting on borderlands and i will kill you ...   \n",
       "2      im coming on borderlands and i will murder you...   \n",
       "3      im getting on borderlands 2 and i will murder ...   \n",
       "4      im getting into borderlands and i can murder y...   \n",
       "...                                                  ...   \n",
       "74676  Just realized that the Windows partition of my...   \n",
       "74677  Just realized that my Mac window partition is ...   \n",
       "74678  Just realized the windows partition of my Mac ...   \n",
       "74679  Just realized between the windows partition of...   \n",
       "74680  Just like the windows partition of my Mac is l...   \n",
       "\n",
       "                                       processed_content  \n",
       "0                                      come border kill   \n",
       "1                                im get borderland kill   \n",
       "2                             im come borderland murder   \n",
       "3                             im get borderland  murder   \n",
       "4                              im get borderland murder   \n",
       "...                                                  ...  \n",
       "74676  realiz window partit mac like  year behind nvi...  \n",
       "74677  realiz mac window partit  year behind nvidia d...  \n",
       "74678  realiz window partit mac  year behind nvidia d...  \n",
       "74679  realiz window partit mac like  year behind nvi...  \n",
       "74680  like window partit mac like  year behind drive...  \n",
       "\n",
       "[74681 rows x 5 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce61f7bb-f502-4021-8c8d-aee959987249",
   "metadata": {},
   "source": [
    "### 2. Encode your Data vectors By using Word2vec (CBOW, Skip Gram), Bag Of words, TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c40d49d8-9381-4386-807a-b951c31ddd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of Words\n",
    "vectorizer = CountVectorizer()\n",
    "X_bow = vectorizer.fit_transform(data2['processed_content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f929a3df-a570-4e66-b168-7a90eb4fcfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(data2['processed_content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "78a4bbe3-3280-40d0-9d7e-fddbc089cfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec\n",
    "tokenized_sentences = [sentence.split() for sentence in data2['processed_content']]\n",
    "w2v_model_cbow = Word2Vec(sentences=tokenized_sentences, vector_size=100, window=5, min_count=1, sg=0)\n",
    "w2v_model_sg = Word2Vec(sentences=tokenized_sentences, vector_size=100, window=5, min_count=1, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "10c9e5b4-376b-4cd0-8d6e-4418fad8035e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_w2v_embeddings(model, sentences):\n",
    "    return np.array([np.mean([model.wv[word] for word in sentence if word in model.wv] or [np.zeros(model.vector_size)], axis=0) for sentence in sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "49c72df8-2df6-4a50-b0eb-5e072f61d509",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_w2v_cbow2 = get_w2v_embeddings(w2v_model_cbow, tokenized_sentences)\n",
    "X_w2v_sg2 = get_w2v_embeddings(w2v_model_sg, tokenized_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b05a76e4-2a10-465d-b284-dc5c64b5dc92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.15772794,  0.17184432, -0.16873311, ..., -0.04625983,\n",
       "         0.06885529,  0.20768587],\n",
       "       [ 0.20528355, -0.11733584,  0.2324743 , ...,  0.64664876,\n",
       "         0.02750003,  0.42811283],\n",
       "       [ 0.26824495,  0.10146496,  0.11087167, ...,  0.16287251,\n",
       "         0.01613133,  0.60663819],\n",
       "       ...,\n",
       "       [-0.32512957,  0.23342772,  0.06513016, ..., -0.35964876,\n",
       "         0.43479013, -0.22112891],\n",
       "       [-0.182026  ,  0.19504462,  0.09219808, ..., -0.16056563,\n",
       "         0.40073925, -0.08028491],\n",
       "       [-0.13186988,  0.00783164, -0.0214451 , ..., -0.28512508,\n",
       "         0.41052717, -0.23579676]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_w2v_cbow2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f1772eec-af56-458e-bcee-98af9164d3b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.09454937,  0.14258991, -0.28380325, ..., -0.59560746,\n",
       "         0.14900042, -0.24600224],\n",
       "       [ 0.03235743, -0.06214147, -0.1253245 , ..., -0.23732491,\n",
       "         0.2931959 , -0.25063777],\n",
       "       [ 0.02390607, -0.12133534, -0.13656086, ..., -0.46497563,\n",
       "         0.17607211, -0.13238272],\n",
       "       ...,\n",
       "       [ 0.02376175,  0.2764942 ,  0.01441227, ..., -0.00140629,\n",
       "         0.108045  , -0.15695462],\n",
       "       [ 0.06266104,  0.21679495,  0.00082671, ..., -0.01905343,\n",
       "         0.03295258, -0.12132229],\n",
       "       [-0.08128785,  0.15623444, -0.05475162, ..., -0.1111027 ,\n",
       "        -0.06731769, -0.27045125]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_w2v_sg2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f04821-0000-4ee2-8ff0-42b75decc5b2",
   "metadata": {},
   "source": [
    "### 3. Train your models by using SVM, Naive Bayes, Logistic Regression, Ada Boosting Algorithms (The embedding will be done by Word2Vec)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "898881e8-147b-4587-b431-1501cf0e68bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data2['Sentiment']\n",
    "\n",
    "X_train_w2v_cbow, X_test_w2v_cbow, y_train, y_test = train_test_split(X_w2v_cbow2, y, test_size=0.2, random_state=42)\n",
    "X_train_w2v_sg, X_test_w2v_sg, y_train, y_test = train_test_split(X_w2v_sg2, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bffbc6dd-2af7-44c6-a12a-c18e511f2315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode target labels with value between 0 and n_classes-1\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1d0cf544-dd69-48c1-87e2-96873e95101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    'SVM': SVC(probability=True),  # probability=True to enable predict_proba\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'AdaBoost': AdaBoostClassifier(),\n",
    "    'GaussianNB': GaussianNB()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "67c8f23b-5049-4858-9923-386b9dc23a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate(models, X_train, X_test, y_train, y_test):\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            proba_predictions = model.predict_proba(X_test)\n",
    "            loss = log_loss(y_test, proba_predictions)\n",
    "        else:\n",
    "            loss = 'N/A'  # log_loss is not applicable if predict_proba is not available\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        f1 = f1_score(y_test, predictions, average='weighted')\n",
    "        \n",
    "        results[name] = {\n",
    "            'accuracy': accuracy,\n",
    "            'f1_score': f1,\n",
    "            'log_loss': loss\n",
    "        }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c52b5a13-a34e-48fa-ac84-e1d307136b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "results_w2v_cbow = train_evaluate(models, X_train_w2v_cbow, X_test_w2v_cbow, y_train, y_test)\n",
    "results_w2v_sg = train_evaluate(models, X_train_w2v_sg, X_test_w2v_sg, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de20ed3a-e74d-4c97-abc6-d4d597d2c43f",
   "metadata": {},
   "source": [
    "### 4. Evaluate the four languages models by using standards metrics (Accuracy, Loss, F1 Score, etc) and other metrics like blue score, choose the best model then argument your choice ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "372ba7a3-d55d-4e54-9532-e3b23b2502ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results using CBOW Word2Vec:\n",
      "SVM: Accuracy = 0.5556001874539733, F1 Score = 0.5355931436614982, Log Loss = N/A\n",
      "Logistic Regression: Accuracy = 0.5196491932784361, F1 Score = 0.49936412831160126, Log Loss = 1.134806378331216\n",
      "AdaBoost: Accuracy = 0.48845149628439444, F1 Score = 0.4693316588668781, Log Loss = 1.376027518226499\n",
      "GaussianNB: Accuracy = 0.45645042511883244, F1 Score = 0.459084092042814, Log Loss = 5.615844078866015\n"
     ]
    }
   ],
   "source": [
    "print(\"Results using CBOW Word2Vec:\")\n",
    "for model_name, metrics in results_w2v_cbow.items():\n",
    "    print(f\"{model_name}: Accuracy = {metrics['accuracy']}, F1 Score = {metrics['f1_score']}, Log Loss = {metrics['log_loss']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "71d73a73-cf03-4c76-a9d9-04e7bac9b87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results using Skip Gram Word2Vec:\n",
      "SVM: Accuracy = 0.6050746468501038, F1 Score = 0.5951686037001309, Log Loss = N/A\n",
      "Logistic Regression: Accuracy = 0.5292896833366807, F1 Score = 0.5142167952155778, Log Loss = 1.109191432778566\n",
      "AdaBoost: Accuracy = 0.4905938274084488, F1 Score = 0.47663146696554326, Log Loss = 1.3749419409901256\n",
      "GaussianNB: Accuracy = 0.46475195822454307, F1 Score = 0.46450385589279747, Log Loss = 3.105669744941258\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nResults using Skip Gram Word2Vec:\")\n",
    "for model_name, metrics in results_w2v_sg.items():\n",
    "    print(f\"{model_name}: Accuracy = {metrics['accuracy']}, F1 Score = {metrics['f1_score']}, Log Loss = {metrics['log_loss']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b3be3c-ce1e-44a2-a4d4-23435f021cdd",
   "metadata": {},
   "source": [
    "The SVM model with Skip Gram Word2Vec embeddings has the highest accuracy and F1 score among all tested models and configurations. This indicates that the SVM model is better at correctly classifying tweets and maintaining a balance between precision and recall.\n",
    "\n",
    "Although Logistic Regression has a slightly lower accuracy and F1 score compared to SVM, it provides a low log loss value. Log loss is a crucial metric for evaluating the confidence of predictions. The lower the log loss, the better the model is at providing accurate probability estimates. This is important in scenarios where not only the classification but also the probability of belonging to each class is important"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0d8e9f-1b1e-400b-8d1c-5cc5b90a65b8",
   "metadata": {},
   "source": [
    "### 5. Interpret the Obtained Results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b278fc5-617a-49d6-86bf-bd11248aa0f6",
   "metadata": {},
   "source": [
    "SVM with Skipgram Word2Vec achieves the best overall performance in terms of accuracy and F1 score. The higher accuracy and F1 score suggest that the model is effective in handling the data's complexity and nuances.Skip Gram tends to work better in scenarios where the relationship between words (context) is more complex, possibly leading to better feature representations for SVM.\n",
    "\n",
    "Logistic Regression provides probability estimates for each class, which is useful for understanding the model's confidence in its predictions. The relatively low log loss value indicates that the model's probability predictions are reliable.Logistic Regression is straightforward to interpret, making it a suitable choice when model transparency is required.\n",
    "\n",
    "Both AdaBoost and GaussianNB show lower accuracy and F1 scores compared to SVM and Logistic Regression. GaussianNB particularly performs poorly with a very high log loss value in the CBOW setup, indicating it struggles with the given dataset and embeddings."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
